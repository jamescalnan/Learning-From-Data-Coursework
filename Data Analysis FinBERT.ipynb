{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.18) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-11-29 18:00:42.292790: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 18:00:42.855692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>negative</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>negative</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>negative</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>negative</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                               text\n",
       "0      neutral  According to Gran , the company has no plans t...\n",
       "1      neutral  Technopolis plans to develop in stages an area...\n",
       "2     negative  The international electronic industry company ...\n",
       "3     positive  With the new production plant the company woul...\n",
       "4     positive  According to the company 's updated strategy f...\n",
       "...        ...                                                ...\n",
       "4841  negative  LONDON MarketWatch -- Share prices ended lower...\n",
       "4842   neutral  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844  negative  Net sales of the Paper segment decreased to EU...\n",
       "4845  negative  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('all-data.csv', encoding='unicode_escape', names=['sentiment', 'text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data into an X, y format\n",
    "X = df['text'].to_list()\n",
    "y = df['sentiment'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download finbert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|\u001b[32m██████████\u001b[0m| 4846/4846 [04:25<00:00, 18.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Predict the sentiment\n",
    "predictions = []\n",
    "prediction_probs = []\n",
    "\n",
    "tokenizer_kwargs = {'padding': True, 'truncation': True, 'max_length': 512}\n",
    "\n",
    "# Replace the rich progress bar with a tqdm progress bar\n",
    "for x in tqdm(X, desc=\"Processing\", colour=\"green\"):\n",
    "    with torch.no_grad():\n",
    "        input_sequence = tokenizer(x, return_tensors=\"pt\", **tokenizer_kwargs)\n",
    "        logits = model(**input_sequence).logits\n",
    "        scores = {\n",
    "            k: v\n",
    "            for k, v in zip(\n",
    "                model.config.id2label.values(),\n",
    "                scipy.special.softmax(logits.numpy().squeeze()),\n",
    "            )\n",
    "        }\n",
    "    sentimentFinbert = max(scores, key=scores.get)\n",
    "    probabilityFinbert = max(scores.values())\n",
    "    predictions.append(sentimentFinbert)\n",
    "    prediction_probs.append(probabilityFinbert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.889</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accuracy: \u001b[1;36m0.889\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the accuracy score\n",
    "from rich import print\n",
    "print(f\"Accuracy: {accuracy_score(y, predictions):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">              precision    recall  f1-score   support\n",
       "\n",
       "    negative       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.80</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.88</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">604</span>\n",
       "     neutral       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.86</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2879</span>\n",
       "    positive       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.81</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.92</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.86</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1363</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.89</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4846</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.86</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.92</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.88</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4846</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.90</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.89</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.89</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4846</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "    negative       \u001b[1;36m0.80\u001b[0m      \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.88\u001b[0m       \u001b[1;36m604\u001b[0m\n",
       "     neutral       \u001b[1;36m0.96\u001b[0m      \u001b[1;36m0.86\u001b[0m      \u001b[1;36m0.91\u001b[0m      \u001b[1;36m2879\u001b[0m\n",
       "    positive       \u001b[1;36m0.81\u001b[0m      \u001b[1;36m0.92\u001b[0m      \u001b[1;36m0.86\u001b[0m      \u001b[1;36m1363\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.89\u001b[0m      \u001b[1;36m4846\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.86\u001b[0m      \u001b[1;36m0.92\u001b[0m      \u001b[1;36m0.88\u001b[0m      \u001b[1;36m4846\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.90\u001b[0m      \u001b[1;36m0.89\u001b[0m      \u001b[1;36m0.89\u001b[0m      \u001b[1;36m4846\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "# Define the FinbertClassifier class\n",
    "class FinbertClassifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_path=\"ProsusAI/finbert\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    def predict(self, texts):\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        return predictions.numpy()\n",
    "\n",
    "# Create a pipeline\n",
    "finbert_pipeline = Pipeline([\n",
    "    ('finbert', FinbertClassifier())\n",
    "])\n",
    "\n",
    "# Save the pipeline\n",
    "with open(\"models/finbert_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(finbert_pipeline, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# with open(\"models/finbert_pipeline.pkl\", \"rb\") as f:\n",
    "#     finbert_pred_pipeline = pickle.load(f)\n",
    "    \n",
    "# predictions = finbert_pred_pipeline.predict(df['headline'].to_list())\n",
    "# predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
